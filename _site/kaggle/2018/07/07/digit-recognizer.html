<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.4.0 -->
<title>Kaggle: Digit Recognition | Keanu Nichols Blog</title>
<meta name="generator" content="Jekyll v3.7.3" />
<meta property="og:title" content="Kaggle: Digit Recognition" />
<meta name="author" content="Keanu Nichols" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="So this blog post is actully going to be a little different because this has nothing to do with GSOC(Google Summer of Code) but well it could because some of the projects have to deal with NLP(Natural Language Processing) but for now we will be dealing with a competition relating to digit recognition. So essentially we want to teach the computer to be able to read hand written digits. The images generated are a 28 * 28 image that is in grey scale. Now working on the project was myself Keanu Nichols and Akil Hosang we used a Neural Network approach and we tried to model it after the Coursera Machine Learning (ML) course by Andrew Ng. We did a very simple implentation by the way, it was for us to simply work on a problem since we were working on the ML course and wanted to get some actual experience working on a project so we looked to Kaggle and one of the beginner projects was this. Overtime I hope we can improve the score of this approach which I believe is possible. So let’s dive into it." />
<meta property="og:description" content="So this blog post is actully going to be a little different because this has nothing to do with GSOC(Google Summer of Code) but well it could because some of the projects have to deal with NLP(Natural Language Processing) but for now we will be dealing with a competition relating to digit recognition. So essentially we want to teach the computer to be able to read hand written digits. The images generated are a 28 * 28 image that is in grey scale. Now working on the project was myself Keanu Nichols and Akil Hosang we used a Neural Network approach and we tried to model it after the Coursera Machine Learning (ML) course by Andrew Ng. We did a very simple implentation by the way, it was for us to simply work on a problem since we were working on the ML course and wanted to get some actual experience working on a project so we looked to Kaggle and one of the beginner projects was this. Overtime I hope we can improve the score of this approach which I believe is possible. So let’s dive into it." />
<link rel="canonical" href="http://localhost:4000/kaggle/2018/07/07/digit-recognizer.html" />
<meta property="og:url" content="http://localhost:4000/kaggle/2018/07/07/digit-recognizer.html" />
<meta property="og:site_name" content="Keanu Nichols Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-07-07T06:20:00-04:00" />
<script type="application/ld+json">
{"description":"So this blog post is actully going to be a little different because this has nothing to do with GSOC(Google Summer of Code) but well it could because some of the projects have to deal with NLP(Natural Language Processing) but for now we will be dealing with a competition relating to digit recognition. So essentially we want to teach the computer to be able to read hand written digits. The images generated are a 28 * 28 image that is in grey scale. Now working on the project was myself Keanu Nichols and Akil Hosang we used a Neural Network approach and we tried to model it after the Coursera Machine Learning (ML) course by Andrew Ng. We did a very simple implentation by the way, it was for us to simply work on a problem since we were working on the ML course and wanted to get some actual experience working on a project so we looked to Kaggle and one of the beginner projects was this. Overtime I hope we can improve the score of this approach which I believe is possible. So let’s dive into it.","author":{"@type":"Person","name":"Keanu Nichols"},"@type":"BlogPosting","url":"http://localhost:4000/kaggle/2018/07/07/digit-recognizer.html","headline":"Kaggle: Digit Recognition","dateModified":"2018-07-07T06:20:00-04:00","datePublished":"2018-07-07T06:20:00-04:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/kaggle/2018/07/07/digit-recognizer.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Keanu Nichols Blog" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Keanu Nichols Blog</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a><a class="page-link" href="/portfolio/">Porfolio</a><a class="page-link" href="/temp/">temp</a></div>
      </nav></div>
</header>
<!-- Begin Jekyll SEO tag v2.4.0 -->
<title>Kaggle: Digit Recognition | Keanu Nichols Blog</title>
<meta name="generator" content="Jekyll v3.7.3" />
<meta property="og:title" content="Kaggle: Digit Recognition" />
<meta name="author" content="Keanu Nichols" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="So this blog post is actully going to be a little different because this has nothing to do with GSOC(Google Summer of Code) but well it could because some of the projects have to deal with NLP(Natural Language Processing) but for now we will be dealing with a competition relating to digit recognition. So essentially we want to teach the computer to be able to read hand written digits. The images generated are a 28 * 28 image that is in grey scale. Now working on the project was myself Keanu Nichols and Akil Hosang we used a Neural Network approach and we tried to model it after the Coursera Machine Learning (ML) course by Andrew Ng. We did a very simple implentation by the way, it was for us to simply work on a problem since we were working on the ML course and wanted to get some actual experience working on a project so we looked to Kaggle and one of the beginner projects was this. Overtime I hope we can improve the score of this approach which I believe is possible. So let’s dive into it." />
<meta property="og:description" content="So this blog post is actully going to be a little different because this has nothing to do with GSOC(Google Summer of Code) but well it could because some of the projects have to deal with NLP(Natural Language Processing) but for now we will be dealing with a competition relating to digit recognition. So essentially we want to teach the computer to be able to read hand written digits. The images generated are a 28 * 28 image that is in grey scale. Now working on the project was myself Keanu Nichols and Akil Hosang we used a Neural Network approach and we tried to model it after the Coursera Machine Learning (ML) course by Andrew Ng. We did a very simple implentation by the way, it was for us to simply work on a problem since we were working on the ML course and wanted to get some actual experience working on a project so we looked to Kaggle and one of the beginner projects was this. Overtime I hope we can improve the score of this approach which I believe is possible. So let’s dive into it." />
<link rel="canonical" href="http://localhost:4000/kaggle/2018/07/07/digit-recognizer.html" />
<meta property="og:url" content="http://localhost:4000/kaggle/2018/07/07/digit-recognizer.html" />
<meta property="og:site_name" content="Keanu Nichols Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-07-07T06:20:00-04:00" />
<script type="application/ld+json">
{"description":"So this blog post is actully going to be a little different because this has nothing to do with GSOC(Google Summer of Code) but well it could because some of the projects have to deal with NLP(Natural Language Processing) but for now we will be dealing with a competition relating to digit recognition. So essentially we want to teach the computer to be able to read hand written digits. The images generated are a 28 * 28 image that is in grey scale. Now working on the project was myself Keanu Nichols and Akil Hosang we used a Neural Network approach and we tried to model it after the Coursera Machine Learning (ML) course by Andrew Ng. We did a very simple implentation by the way, it was for us to simply work on a problem since we were working on the ML course and wanted to get some actual experience working on a project so we looked to Kaggle and one of the beginner projects was this. Overtime I hope we can improve the score of this approach which I believe is possible. So let’s dive into it.","author":{"@type":"Person","name":"Keanu Nichols"},"@type":"BlogPosting","url":"http://localhost:4000/kaggle/2018/07/07/digit-recognizer.html","headline":"Kaggle: Digit Recognition","dateModified":"2018-07-07T06:20:00-04:00","datePublished":"2018-07-07T06:20:00-04:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/kaggle/2018/07/07/digit-recognizer.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Kaggle: Digit Recognition</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2018-07-07T06:20:00-04:00" itemprop="datePublished">Jul 7, 2018
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p><br />
So this blog post is actully going to be a little different because this has nothing to do with GSOC(Google Summer of Code) but well it could because some of the projects have to deal with NLP(Natural Language Processing) but for now we will be dealing with a competition relating to digit recognition. So essentially we want to teach the computer to be able to read hand written digits. The images generated are a 28 * 28 image that is in grey scale. Now working on the project was myself Keanu Nichols and <a href="">Akil Hosang</a> we used a Neural Network approach and we tried to model it after the Coursera Machine Learning (ML) course by Andrew Ng. We did a very simple implentation by the way, it was for us to simply work on a problem since we were working on the ML course and wanted to get some actual experience working on a project so we looked to <a href="">Kaggle</a> and one of the beginner projects was this. Overtime I hope we can improve the score of this approach which I believe is possible. So let’s dive into it.</p>

<p>First we go about importing our different modules as seen below, pandas is used for dataframes to store the pixels of the images and do a number of different operations. Matplotlib is used to actually see the image using the dataframes storing the pixels. Numpy is used to manipulate array to do things like transposing a matrix or multiplying two matrices. Random is used to give random numbers as will be seen in the function “randInit”. And finally minimize which is an equivalent to fmincg in matlab which is used to train the actual Neural Network.</p>

<figure class="highlight">
  <pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre></td><td class="code"><pre><span class="c"># Plot ad hoc mnist instances</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span></pre></td></tr></tbody></table></code></pre>
</figure>

<p>Then we go onto loading our data into a training set</p>

<figure class="highlight">
  <pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="code"><pre><span class="c"># load (downloaded if needed) the Kaggle dataset</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'./datasets/train.csv'</span><span class="p">)</span>
<span class="n">train</span><span class="o">.</span><span class="n">head</span><span class="p">()</span></pre></td></tr></tbody></table></code></pre>
</figure>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>label</th>
      <th>pixel0</th>
      <th>pixel1</th>
      <th>pixel2</th>
      <th>pixel3</th>
      <th>pixel4</th>
      <th>pixel5</th>
      <th>pixel6</th>
      <th>pixel7</th>
      <th>pixel8</th>
      <th>...</th>
      <th>pixel774</th>
      <th>pixel775</th>
      <th>pixel776</th>
      <th>pixel777</th>
      <th>pixel778</th>
      <th>pixel779</th>
      <th>pixel780</th>
      <th>pixel781</th>
      <th>pixel782</th>
      <th>pixel783</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
  <p>5 rows × 785 columns</p>
</div>

<p>and test set.</p>

<figure class="highlight">
  <pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
</pre></td><td class="code"><pre><span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'./datasets/test.csv'</span><span class="p">)</span>
<span class="n">test</span><span class="o">.</span><span class="n">head</span><span class="p">()</span></pre></td></tr></tbody></table></code></pre>
</figure>

<div>
  <style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

  <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>pixel0</th>
      <th>pixel1</th>
      <th>pixel2</th>
      <th>pixel3</th>
      <th>pixel4</th>
      <th>pixel5</th>
      <th>pixel6</th>
      <th>pixel7</th>
      <th>pixel8</th>
      <th>pixel9</th>
      <th>...</th>
      <th>pixel774</th>
      <th>pixel775</th>
      <th>pixel776</th>
      <th>pixel777</th>
      <th>pixel778</th>
      <th>pixel779</th>
      <th>pixel780</th>
      <th>pixel781</th>
      <th>pixel782</th>
      <th>pixel783</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
  <p>5 rows × 784 columns</p>
</div>

<p>Since we would want to just have the pixels we take the first column and onwards to get all the pixel data and store it in X_train. We then store the labels of the numbers for e.g. if the number is 2 or 3 and we store that in y_train. After we train our test date into X_test, we will actually feed this to the Neural Nwtwork and get our outputs and submit to Kaggle.</p>

<figure class="highlight">
  <pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="code"><pre><span class="n">X_train</span> <span class="o">=</span> <span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s">'float32'</span><span class="p">))</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s">'int32'</span><span class="p">))</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s">'float32'</span><span class="p">)</span></pre></td></tr></tbody></table></code></pre>
</figure>

<p>Now the order in which I do this will not be the exact formate of the jupyter notebook but this is for us to better understand the order in which it is executed. So the first part is to store our data into the Neural Network class.</p>

<figure class="highlight">
  <pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
</pre></td><td class="code"><pre><span class="n">nn</span> <span class="o">=</span> <span class="n">Neural_Network</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">y_train</span><span class="p">))</span></pre></td></tr></tbody></table></code></pre>
</figure>

<p>The Neural_Network class looks like this and we see that it’s initialized with m the number of inputs which in our case will be 784 (28 * 28) our input layer is set to 784, hidden layer is 25 (was used in the exercise for the ML course) and our output layer size is 10 (because we have 10 digits 0-9). Epsilon is what we’re going to calculate soon enough. J is our cost function and grad is our graident. Num_labels I think is self explanitory the number of labels and lambda1 is lambda which will be used in both forward and back propagation, iter is used when we are going through using minimize for us to see our iteration number of training the Neural Network.</p>

<figure class="highlight">
  <pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td class="code"><pre><span class="k">class</span> <span class="nc">Neural_Network</span><span class="p">:</span>
    <span class="c">#The Neural_Network class we use to store all the values that</span>
    <span class="c">#will be used to teach our model to start recognizing handwritten</span>
    <span class="c">#digits</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_layer_size</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_size</span> <span class="o">=</span> <span class="mi">25</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_layer_size</span> <span class="o">=</span> <span class="mi">10</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">J</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="mi">10</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lambda1</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="nb">iter</span> <span class="o">=</span> <span class="mi">0</span></pre></td></tr></tbody></table></code></pre>
</figure>

<p>So we go forward actually getting theta1 (for our pixels) and theta2 (for our number labels). We wil call the function “randInit()” to actually populate it with values.</p>

<figure class="highlight">
  <pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
</pre></td><td class="code"><pre><span class="n">theta1</span> <span class="o">=</span> <span class="n">theta2</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">theta1</span><span class="p">,</span><span class="n">theta2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">randInit</span><span class="p">()</span></pre></td></tr></tbody></table></code></pre>
</figure>

<p>We first go out getting our values for epsilon, which was given by the <a href="">ML course</a> (under Random Initialization), we split it for theta1 and theta2 that’s why epsilon is a list of two values. We also add our bias unit. We then store our values for theta1 and theta2 by random initalization. It is more or less using what’s in the course.</p>

<figure class="highlight">
  <pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
</pre></td><td class="code"><pre>    <span class="k">def</span> <span class="nf">randInit</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">theta1</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">theta2</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
            <span class="k">if</span><span class="p">(</span><span class="n">x</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                <span class="n">L_in</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_layer_size</span>
                <span class="n">L_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_size</span>
            <span class="k">if</span><span class="p">(</span><span class="n">x</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>
                <span class="n">L_in</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_size</span>
                <span class="n">L_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layer_size</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">L_in</span> <span class="o">+</span> <span class="n">L_out</span><span class="p">))</span>
            
        <span class="n">X_bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_layer_size</span> <span class="o">+</span> <span class="mi">1</span>
        
        <span class="n">theta1</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_size</span><span class="p">,</span>
                 <span class="bp">self</span><span class="o">.</span><span class="n">input_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                 <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">theta2</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_layer_size</span><span class="p">,</span>
                  <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
                  <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> 
        <span class="k">return</span> <span class="n">theta1</span><span class="p">,</span><span class="n">theta2</span></pre></td></tr></tbody></table></code></pre>
</figure>

<p>The next part is the go ahead and actually train the Neural Network. As seen below we first format the values of theta1 and theta2 and store it so we can use it in different parts of the program, I also used it because the function we will be using called minimize which actually trains the Neural Network want theta1 and theta2 to be store in this format so we store it in nn_params (line 1). The next step is to actually go ahead and train the network (line 2).</p>

<figure class="highlight">
  <pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
</pre></td><td class="code"><pre><span class="n">nn_params</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">theta1</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">theta1</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s">'F'</span><span class="p">),</span> <span class="n">theta2</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">theta2</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s">'F'</span><span class="p">)))</span>
<span class="n">theta1</span><span class="p">,</span><span class="n">theta2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">theta1</span><span class="p">,</span><span class="n">theta2</span><span class="p">,</span><span class="n">nn_params</span><span class="p">,</span><span class="n">X_train</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">y_train</span><span class="p">),</span><span class="mf">0.08</span><span class="p">)</span></pre></td></tr></tbody></table></code></pre>
</figure>

<p>So as we see here train is used to better adjust the values of theta1 and theta2. So we will be using the function minimize which will be using the function nnCostFunction and that will return the cost and gradient each time. Minimize actually is able to detect if the cost function is decreasing and if it isn’t it will adjust accordingly.</p>

<figure class="highlight">
  <pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
</pre></td><td class="code"><pre><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">theta1</span><span class="p">,</span><span class="n">theta2</span><span class="p">,</span><span class="n">nn_params</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lambda_reg</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">J</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'Training Neural Network...'</span><span class="p">)</span>
        <span class="n">maxiter</span> <span class="o">=</span> <span class="mi">20</span>
        <span class="c">#maxiter = 30</span>
        <span class="c">#maxiter = 60</span>
        <span class="c">#maxiter = 5</span>
        <span class="c">#lambda_reg = 0</span>
        <span class="n">nn_params</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">theta1</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">theta1</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s">'F'</span><span class="p">),</span> <span class="n">theta2</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">theta2</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s">'F'</span><span class="p">)))</span>
        <span class="n">myargs</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_layer_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lambda_reg</span><span class="p">)</span>
        <span class="n">results</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nnCostFunction</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="n">nn_params</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="n">myargs</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s">'disp'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> <span class="s">'maxiter'</span><span class="p">:</span><span class="n">maxiter</span><span class="p">},</span> <span class="n">method</span><span class="o">=</span><span class="s">"L-BFGS-B"</span><span class="p">,</span> <span class="n">jac</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="n">nn_params</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s">"x"</span><span class="p">]</span>

        <span class="c"># Obtain Theta1 and Theta2 back from nn_params</span>
        <span class="n">Theta1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">nn_params</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_size</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)],</span> \
                         <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">order</span><span class="o">=</span><span class="s">'F'</span><span class="p">)</span>

        <span class="n">Theta2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">nn_params</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_size</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):],</span> \
                         <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">order</span><span class="o">=</span><span class="s">'F'</span><span class="p">)</span>

        <span class="k">print</span><span class="p">(</span><span class="s">'Program paused. Press enter to continue.</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Theta1</span><span class="p">,</span><span class="n">Theta2</span></pre></td></tr></tbody></table></code></pre>
</figure>

<p>So we will look at the nnCostFunction the first part is to computer forward propagation. We first unpack nn_params and then add a bias unit to both theta1 and theta2. We then go about calculating the activation function ffrom the input layer to the hidden layer and then we do it for the hidden layer to the output layer.
We then create a create a matrix that will have 10 labels and will have 0’s in all positions except one which will have 1 which represents what digit the pixels form. We then can calculate the cost function we also use regularization to stop overfitting.</p>

<figure class="highlight">
  <pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
</pre></td><td class="code"><pre><span class="k">def</span> <span class="nf">nnCostFunction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">nn_params</span><span class="p">,</span> <span class="n">input_layer_size</span><span class="p">,</span> <span class="n">hidden_layer_size</span><span class="p">,</span> \
                       <span class="n">num_labels</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lambda_reg</span><span class="p">):</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">J</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="bp">self</span><span class="o">.</span><span class="nb">iter</span><span class="o">+=</span><span class="mi">1</span><span class="p">;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lambda1</span> <span class="o">=</span> <span class="n">lambda_reg</span>

        
        <span class="n">theta1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">nn_params</span><span class="p">[:</span><span class="n">hidden_layer_size</span> <span class="o">*</span> <span class="p">(</span><span class="n">input_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)],</span> \
                     <span class="p">(</span><span class="n">hidden_layer_size</span><span class="p">,</span> <span class="n">input_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">order</span><span class="o">=</span><span class="s">'F'</span><span class="p">)</span>

        <span class="n">theta2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">nn_params</span><span class="p">[</span><span class="n">hidden_layer_size</span> <span class="o">*</span> <span class="p">(</span><span class="n">input_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):],</span> \
                     <span class="p">(</span><span class="n">num_labels</span><span class="p">,</span> <span class="n">hidden_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">order</span><span class="o">=</span><span class="s">'F'</span><span class="p">)</span>
        
        <span class="n">Theta1_grad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span> <span class="n">theta1</span><span class="o">.</span><span class="n">shape</span> <span class="p">)</span>
        <span class="n">Theta2_grad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span> <span class="n">theta2</span><span class="o">.</span><span class="n">shape</span> <span class="p">)</span>
        
        <span class="n">a1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span> <span class="n">X</span><span class="p">))</span>
        
        <span class="n">z2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">a1</span><span class="p">,</span> <span class="n">theta1</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        
        <span class="n">a2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">z2</span><span class="p">)</span>
        
        <span class="n">a2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">a2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">)),</span> <span class="n">a2</span><span class="p">))</span>
        
        <span class="n">z3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">a2</span><span class="p">,</span> <span class="n">theta2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        
        <span class="n">a3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">z3</span><span class="p">)</span>

        <span class="n">numLabels_temp</span> <span class="o">=</span> <span class="n">y</span>
    
        <span class="n">yMatrix</span> <span class="o">=</span> <span class="n">y</span>
        <span class="n">yMatrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span><span class="p">))</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">):</span>
            <span class="n">yMatrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">numLabels_temp</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
             
        <span class="n">cost</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">):</span>
            <span class="n">cost</span> <span class="o">+=</span>  <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span> <span class="n">yMatrix</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">a3</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">yMatrix</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">a3</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="p">)</span>
            
        <span class="n">sqTheta1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">theta1</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:]</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">sqTheta2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">theta2</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:]</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">J</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="mf">1.0</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">cost</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">J</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">J</span> <span class="o">+</span> <span class="p">(</span> <span class="p">(</span><span class="n">lambda_reg</span><span class="o">/</span><span class="p">(</span><span class="mf">2.0</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">))</span> <span class="o">*</span><span class="p">(</span><span class="n">sqTheta1</span> <span class="o">+</span> <span class="n">sqTheta2</span><span class="p">)</span> <span class="p">)</span>
            
        <span class="k">print</span><span class="p">(</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="nb">iter</span><span class="p">)</span> <span class="o">+</span> <span class="s">") "</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">J</span><span class="p">,</span><span class="s">" cost"</span><span class="p">)</span></pre></td></tr></tbody></table></code></pre>
</figure>

<p>The next step is to do back propagation, so we go ahead and use values we had gotten from the feedforward calculations and use that to better adjust our theta values and we then store that in ‘self.grad’. We do this for 20 iterations, however this can be increased. There starts to become a point where it does not matter how many iterations you do since the values don’t change by much, which happened with our model. This may have been due to overfitting or underfitting, this is a simple model but later we hope to improve on it and do some analysis on what is happening by using for example cross validation.</p>

<figure class="highlight">
  <pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
</pre></td><td class="code"><pre><span class="c">#Back Prop</span>
        <span class="n">delta1</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
        <span class="n">delta2</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> 
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">):</span>
            <span class="c">#print(a1.shape)</span>
            <span class="n">a1_t</span> <span class="o">=</span> <span class="n">a1</span><span class="p">[</span><span class="n">t</span><span class="p">,]</span>
            
            <span class="n">a2_t</span> <span class="o">=</span> <span class="n">a2</span><span class="p">[</span><span class="n">t</span><span class="p">,]</span><span class="o">.</span><span class="n">T</span>
            
            <span class="n">a3_t</span> <span class="o">=</span> <span class="n">a3</span><span class="p">[</span><span class="n">t</span><span class="p">,]</span><span class="o">.</span><span class="n">T</span>
            
            <span class="n">y_output_t</span> <span class="o">=</span> <span class="n">yMatrix</span><span class="p">[</span><span class="n">t</span><span class="p">,]</span><span class="o">.</span><span class="n">T</span>
            
            <span class="n">delta3_t</span> <span class="o">=</span> <span class="p">(</span><span class="n">a3_t</span> <span class="o">-</span> <span class="n">y_output_t</span><span class="p">);</span>
            
            <span class="n">z2_t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">a1_t</span><span class="p">,</span> <span class="n">theta1</span><span class="o">.</span><span class="n">T</span><span class="p">);</span>
            <span class="n">z2_t</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">z2_t</span><span class="p">,</span><span class="mi">0</span> <span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            
            <span class="n">delta2_t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">theta2</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">delta3_t</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoidGradient</span><span class="p">(</span><span class="n">z2_t</span><span class="p">)</span>
            
            <span class="n">delta2_t</span> <span class="o">=</span> <span class="n">delta2_t</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
            
            <span class="n">delta2</span> <span class="o">=</span> <span class="n">delta2</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">delta3_t</span><span class="p">,</span> <span class="n">a2_t</span><span class="p">)</span>
            <span class="n">delta1</span> <span class="o">=</span> <span class="n">delta1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">delta2_t</span><span class="p">,</span> <span class="n">a1_t</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        
        <span class="n">Theta1_grad</span> <span class="o">=</span> <span class="n">delta1</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span>
        <span class="n">Theta2_grad</span> <span class="o">=</span> <span class="n">delta2</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span>
        
        <span class="n">Theta1_grad_unregularized</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">Theta1_grad</span><span class="p">)</span>
        <span class="n">Theta2_grad_unregularized</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">Theta2_grad</span><span class="p">)</span>
        <span class="n">Theta1_grad</span> <span class="o">+=</span> <span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lambda1</span><span class="p">)</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">)</span><span class="o">*</span><span class="n">theta1</span>
        <span class="n">Theta2_grad</span> <span class="o">+=</span> <span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lambda1</span><span class="p">)</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">)</span><span class="o">*</span><span class="n">theta2</span>
        <span class="n">Theta1_grad</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">Theta1_grad_unregularized</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">Theta2_grad</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">Theta2_grad_unregularized</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">Theta1_grad</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">Theta1_grad</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s">'F'</span><span class="p">),</span> <span class="n">Theta2_grad</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">Theta2_grad</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s">'F'</span><span class="p">)))</span>
        <span class="c">#print(Theta2_grad)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">J</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">grad</span></pre></td></tr></tbody></table></code></pre>
</figure>

<p>Our next step is the begin to predict what numbers are represented in our training set.</p>

<figure class="highlight">
  <pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
</pre></td><td class="code"><pre><span class="n">pred</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">theta1</span><span class="p">,</span> <span class="n">theta2</span><span class="p">,</span> <span class="n">X_train</span><span class="p">)</span></pre></td></tr></tbody></table></code></pre>
</figure>

<p>We then compare that to the labels in our training set, as discussed before this may cause a problem with overfitting. We have a accuracy of 76% which to be honest by today’s standard’s doesn’t seem too great but one step at a time!</p>

<figure class="highlight">
  <pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="code"><pre><span class="n">k</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">print</span><span class="p">(</span><span class="n">pred</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">pred</span><span class="p">:</span>
    <span class="k">if</span><span class="p">(</span><span class="n">i</span> <span class="o">==</span> <span class="mi">10</span><span class="p">):</span>
        <span class="n">pred</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">k</span><span class="o">+=</span><span class="mi">1</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Training Set Accuracy: {:f}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span> <span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">pred</span> <span class="o">==</span> <span class="n">y_train</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span> <span class="p">)</span> <span class="p">)</span> <span class="p">)</span></pre></td></tr></tbody></table></code></pre>
</figure>

<p>We then use our model to go ahead and predict for the test set and then we just upload that to the Kaggle website. You will see in the file that we had to do some adjusting since for example the model would predict 10 but this is actually 0.</p>

<figure class="highlight">
  <pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
</pre></td><td class="code"><pre><span class="n">ans</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">theta1</span><span class="p">,</span><span class="n">theta2</span><span class="p">,</span> <span class="n">X_test</span><span class="p">)</span></pre></td></tr></tbody></table></code></pre>
</figure>

<figure class="highlight">
  <pre><code class="language-python" data-lang="python"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre></td><td class="code"><pre><span class="n">k</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">print</span><span class="p">(</span><span class="n">ans</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ans</span><span class="p">:</span>
    <span class="k">if</span><span class="p">(</span><span class="n">i</span> <span class="o">==</span> <span class="mi">10</span><span class="p">):</span>
        <span class="n">ans</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">k</span><span class="o">+=</span><span class="mi">1</span>
<span class="k">print</span><span class="p">(</span><span class="n">ans</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">ans</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">"Label"</span><span class="p">])</span>
<span class="nb">file</span> <span class="o">=</span> <span class="s">"submission0.csv"</span>
<span class="n">df</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c">#df['ImageId'] = df.index</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'ImageId'</span><span class="p">,</span> <span class="s">'Label'</span><span class="p">]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">df</span><span class="p">[</span><span class="s">'ImageId'</span><span class="p">]:</span>
    <span class="n">df</span><span class="p">[</span><span class="s">'ImageId'</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="o">+=</span><span class="mi">1</span>
<span class="c">#for</span>
<span class="k">print</span><span class="p">(</span><span class="n">df</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="nb">file</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span></pre></td></tr></tbody></table></code></pre>
</figure>

<p>Our best score on Kaggle is 0.87914 but this can definitely be increased through different models.</p>

<p>Resources:
GSoC ideas (Specifically Ideas 2 &amp; 3): <a href="https://wiki.linuxfoundation.org/chaoss/gsoc-ideas">Ideas</a><br />
My proposal: <a href="https://github.com/kmn5409/chaoss-microtasks/blob/master/GSoC-2018-Keanu-Nichols-CHAOSS-proposal.pdf">My proposal</a></p>

<p>Files Used:
Python File - <a href="https://github.com/kmn5409/GSoC_CHAOSS/blob/master/Augur/Perceval/PiperReader%2012.py#L149">PiperRead 12</a><br />
Jupyter Notebook - <a href="https://github.com/kmn5409/GSoC_CHAOSS/blob/master/Augur/Perceval/PiperMail%208.ipynb">PiperMail 8</a></p>

<p>Jupyter Notebook - <a href="https://github.com/kmn5409/GSoC_CHAOSS/blob/master/Augur/Perceval/NLP/Sentiment_Piper%206.ipynb">Sentiment_Piper 6</a></p>


  </div><a class="u-url" href="/kaggle/2018/07/07/digit-recognizer.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Keanu Nichols Blog</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Keanu Nichols</li><li><a class="u-email" href="mailto:keanu.nichols@my.uwi.edu">keanu.nichols@my.uwi.edu</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/kmn5409"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">kmn5409</span></a></li><li><a href="https://www.linkedin.com/in/keanu-nichols"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#linkedin"></use></svg> <span class="username">keanu-nichols</span></a></li><li><a href="/feed.xml"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#rss"></use></svg> <span>rss</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>A blog about Keanu Nichols for writing about his school/work experience and projects that he worked on.
</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
